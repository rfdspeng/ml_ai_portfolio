{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea12c521-7dbb-4eb9-8109-d52d40f9e477",
   "metadata": {},
   "source": [
    "# <u>What is the flow?</u>\n",
    "\n",
    "The user asks or says something.\n",
    "* Non-agentic: Encode the user input, retrieve the top results from the vector DB, pass it into the LLM, and then the LLM responds with the given context. For even more control, I can prompt the user with dropdown menus for metadata, although at this point, it's really limiting the deep learning application.\n",
    "* Agentic: The LLM is an agent. It will figure out what it should do - it can respond immediately or it will take the user input and format it into something else. For example, the LLM retrieves the important information from the user input - genre, ratings threshold, author, etc. Then, the LLM creates a new text from the important information, encodes the new text, and queries the vector DB, along with metadata filters.\n",
    "* Semi-agentic: I prompt the LLM with something like \"You are a book recommender. If the user requests something specific, extract the key information from the user request in this format: {\"genre\": some_genre, \"author\": some_author, etc.}. If the user request does not contain a field, like \"author\", do not include it in the dictionary.\" The LLM pulls the key information, and then I encode the user input and query the database with the metadata. So the LLM is not an agent, but it helps with parsing the key information from the user input.\n",
    "\n",
    "How do I include weighting by number of ratings and rating?\n",
    "\n",
    "Let's start from low complexity and build our way up.\n",
    "* 1: Embed user query, retrieve, feed to chatbot. Flask/Fast and Streamlit locally hosted. Where to store conversation history?\n",
    "* 2: Embed user query, retrieve, feed to chatbot. Containerize and deploy using AWS Lambda and AWS App Runner.\n",
    "* 3: Use LLM to extract information from user query for metadata filtering via prompting. Reformat user query, embed, retrieve, feed to chatbot. If user query is not a true query, do not retrieve. Create tools for agentic behavior. Like a function that returns available genres.\n",
    "* 4: Fine-tune smaller model to extract information from user query. Use LLM to provide training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b703d2-9834-486e-9bed-823005544774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
