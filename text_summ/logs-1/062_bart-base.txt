Unfreezing base_model.model.lm_head
Full list of unfrozen weights:
base_model.model.model.shared
base_model.model.model.encoder.embed_tokens
base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_A.default
base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_B.default
base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_A.default
base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_B.default
base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_A.default
base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_B.default
base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_A.default
base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_B.default
base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_A.default
base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_B.default
base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_A.default
base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_B.default
base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_A.default
base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_B.default
base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_A.default
base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_B.default
base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_A.default
base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_B.default
base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_A.default
base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_B.default
base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_A.default
base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_B.default
base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_A.default
base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.embed_tokens
base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_B.default
base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_A.default
base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_B.default
base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_A.default
base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_B.default
base_model.model.lm_head
trainable params: 39,045,888 || all params: 139,862,784 || trainable%: 27.9173
{'loss': 12.5523, 'grad_norm': 1037.6221923828125, 'learning_rate': 0.0015840000000000001, 'epoch': 0.1}
{'loss': 10.6418, 'grad_norm': 47.69181442260742, 'learning_rate': 0.001568, 'epoch': 0.2}
{'loss': 9.7158, 'grad_norm': 22.963232040405273, 'learning_rate': 0.001552, 'epoch': 0.3}
{'loss': 8.8804, 'grad_norm': 11.739574432373047, 'learning_rate': 0.001536, 'epoch': 0.4}
{'loss': 8.7939, 'grad_norm': 10.234219551086426, 'learning_rate': 0.00152, 'epoch': 0.5}
{'loss': 8.4743, 'grad_norm': 6.599090099334717, 'learning_rate': 0.001504, 'epoch': 0.6}
{'loss': 8.1466, 'grad_norm': 6.5213398933410645, 'learning_rate': 0.0014880000000000002, 'epoch': 0.7}
{'loss': 7.8277, 'grad_norm': 24.738561630249023, 'learning_rate': 0.0014720000000000002, 'epoch': 0.8}
{'loss': 7.9139, 'grad_norm': 5.344178199768066, 'learning_rate': 0.001456, 'epoch': 0.9}
{'loss': 7.7157, 'grad_norm': 4.045407295227051, 'learning_rate': 0.00144, 'epoch': 1.0}
{'eval_loss': 7.432661533355713, 'eval_runtime': 3.2228, 'eval_samples_per_second': 40.958, 'eval_steps_per_second': 20.479, 'epoch': 1.0}
{'loss': 7.308, 'grad_norm': 3.3048548698425293, 'learning_rate': 0.0014240000000000001, 'epoch': 1.1}
{'loss': 7.1263, 'grad_norm': 3.4465103149414062, 'learning_rate': 0.0014080000000000002, 'epoch': 1.2}
{'loss': 7.1037, 'grad_norm': 3.512631893157959, 'learning_rate': 0.001392, 'epoch': 1.3}
{'loss': 7.1875, 'grad_norm': 2.9829161167144775, 'learning_rate': 0.001376, 'epoch': 1.4}
{'loss': 7.099, 'grad_norm': 4.358242511749268, 'learning_rate': 0.00136, 'epoch': 1.5}
{'loss': 6.8716, 'grad_norm': 3.0462849140167236, 'learning_rate': 0.001344, 'epoch': 1.6}
{'loss': 6.6661, 'grad_norm': 3.0786824226379395, 'learning_rate': 0.001328, 'epoch': 1.7}
{'loss': 6.9751, 'grad_norm': 2.963754415512085, 'learning_rate': 0.001312, 'epoch': 1.8}
{'loss': 7.3182, 'grad_norm': 2.5204193592071533, 'learning_rate': 0.001296, 'epoch': 1.9}
{'loss': 6.311, 'grad_norm': 5.089548587799072, 'learning_rate': 0.00128, 'epoch': 2.0}
{'eval_loss': 12.605692863464355, 'eval_runtime': 3.3613, 'eval_samples_per_second': 39.271, 'eval_steps_per_second': 19.635, 'epoch': 2.0}
{'loss': 6.4006, 'grad_norm': 2.8896090984344482, 'learning_rate': 0.0012640000000000001, 'epoch': 2.1}
{'loss': 6.595, 'grad_norm': 2.938253402709961, 'learning_rate': 0.0012480000000000002, 'epoch': 2.2}
{'loss': 6.4277, 'grad_norm': 2.8158061504364014, 'learning_rate': 0.001232, 'epoch': 2.3}
{'loss': 6.4706, 'grad_norm': 2.6155803203582764, 'learning_rate': 0.001216, 'epoch': 2.4}
{'loss': 6.4337, 'grad_norm': 3.039654493331909, 'learning_rate': 0.0012000000000000001, 'epoch': 2.5}
{'loss': 6.6325, 'grad_norm': 2.8469293117523193, 'learning_rate': 0.001184, 'epoch': 2.6}
{'loss': 6.2823, 'grad_norm': 2.739656925201416, 'learning_rate': 0.001168, 'epoch': 2.7}
{'loss': 6.37, 'grad_norm': 2.787968635559082, 'learning_rate': 0.001152, 'epoch': 2.8}
{'loss': 6.5555, 'grad_norm': 3.090252637863159, 'learning_rate': 0.001136, 'epoch': 2.9}
{'loss': 6.5857, 'grad_norm': 2.976722002029419, 'learning_rate': 0.00112, 'epoch': 3.0}
{'eval_loss': 7.654211521148682, 'eval_runtime': 3.5262, 'eval_samples_per_second': 37.434, 'eval_steps_per_second': 18.717, 'epoch': 3.0}
{'loss': 6.1688, 'grad_norm': 3.1524014472961426, 'learning_rate': 0.001104, 'epoch': 3.1}
{'loss': 6.1149, 'grad_norm': 3.079697847366333, 'learning_rate': 0.0010880000000000002, 'epoch': 3.2}
{'loss': 6.2358, 'grad_norm': 2.8535356521606445, 'learning_rate': 0.001072, 'epoch': 3.3}
{'loss': 6.5173, 'grad_norm': 2.8492307662963867, 'learning_rate': 0.001056, 'epoch': 3.4}
{'loss': 6.2019, 'grad_norm': 3.019637107849121, 'learning_rate': 0.0010400000000000001, 'epoch': 3.5}
{'loss': 5.9527, 'grad_norm': 3.0145211219787598, 'learning_rate': 0.0010240000000000002, 'epoch': 3.6}
{'loss': 6.3382, 'grad_norm': 2.7360317707061768, 'learning_rate': 0.001008, 'epoch': 3.7}
{'loss': 6.2777, 'grad_norm': 2.7066073417663574, 'learning_rate': 0.000992, 'epoch': 3.8}
{'loss': 6.0722, 'grad_norm': 2.8135323524475098, 'learning_rate': 0.000976, 'epoch': 3.9}
{'loss': 6.3683, 'grad_norm': 2.940723419189453, 'learning_rate': 0.00096, 'epoch': 4.0}
{'eval_loss': 10.057808876037598, 'eval_runtime': 3.585, 'eval_samples_per_second': 36.82, 'eval_steps_per_second': 18.41, 'epoch': 4.0}
{'loss': 6.0413, 'grad_norm': 2.6009604930877686, 'learning_rate': 0.000944, 'epoch': 4.1}
{'loss': 6.2563, 'grad_norm': 2.6483988761901855, 'learning_rate': 0.000928, 'epoch': 4.2}
{'loss': 6.0146, 'grad_norm': 2.7657973766326904, 'learning_rate': 0.0009119999999999999, 'epoch': 4.3}
{'loss': 5.8802, 'grad_norm': 3.228011131286621, 'learning_rate': 0.0008960000000000001, 'epoch': 4.4}
{'loss': 6.0825, 'grad_norm': 3.6947786808013916, 'learning_rate': 0.0008800000000000001, 'epoch': 4.5}
{'loss': 6.0115, 'grad_norm': 2.7558348178863525, 'learning_rate': 0.0008640000000000001, 'epoch': 4.6}
{'loss': 5.9365, 'grad_norm': 3.3606977462768555, 'learning_rate': 0.0008480000000000001, 'epoch': 4.7}
{'loss': 6.1305, 'grad_norm': 2.9737942218780518, 'learning_rate': 0.0008320000000000001, 'epoch': 4.8}
{'loss': 6.3101, 'grad_norm': 2.9131431579589844, 'learning_rate': 0.0008160000000000001, 'epoch': 4.9}
{'loss': 6.0543, 'grad_norm': 2.6983861923217773, 'learning_rate': 0.0008, 'epoch': 5.0}
{'eval_loss': 7.347164630889893, 'eval_runtime': 3.5944, 'eval_samples_per_second': 36.724, 'eval_steps_per_second': 18.362, 'epoch': 5.0}
{'loss': 6.116, 'grad_norm': 2.3521814346313477, 'learning_rate': 0.000784, 'epoch': 5.1}
{'loss': 5.7839, 'grad_norm': 2.9780073165893555, 'learning_rate': 0.000768, 'epoch': 5.2}
{'loss': 6.0181, 'grad_norm': 3.3302714824676514, 'learning_rate': 0.000752, 'epoch': 5.3}
{'loss': 6.0202, 'grad_norm': 3.0251686573028564, 'learning_rate': 0.0007360000000000001, 'epoch': 5.4}
{'loss': 5.9028, 'grad_norm': 3.075076103210449, 'learning_rate': 0.00072, 'epoch': 5.5}
{'loss': 5.9231, 'grad_norm': 3.363518238067627, 'learning_rate': 0.0007040000000000001, 'epoch': 5.6}
{'loss': 6.0642, 'grad_norm': 2.7505605220794678, 'learning_rate': 0.000688, 'epoch': 5.7}
{'loss': 5.9575, 'grad_norm': 2.5693840980529785, 'learning_rate': 0.000672, 'epoch': 5.8}
{'loss': 6.1237, 'grad_norm': 3.0056724548339844, 'learning_rate': 0.000656, 'epoch': 5.9}
{'loss': 5.8128, 'grad_norm': 3.460925817489624, 'learning_rate': 0.00064, 'epoch': 6.0}
{'eval_loss': 7.6345696449279785, 'eval_runtime': 3.5829, 'eval_samples_per_second': 36.842, 'eval_steps_per_second': 18.421, 'epoch': 6.0}
{'loss': 5.9005, 'grad_norm': 3.249828577041626, 'learning_rate': 0.0006240000000000001, 'epoch': 6.1}
{'loss': 5.8781, 'grad_norm': 2.683847427368164, 'learning_rate': 0.000608, 'epoch': 6.2}
{'loss': 5.7432, 'grad_norm': 2.7120490074157715, 'learning_rate': 0.000592, 'epoch': 6.3}
{'loss': 5.8438, 'grad_norm': 3.4487788677215576, 'learning_rate': 0.000576, 'epoch': 6.4}
{'loss': 6.0257, 'grad_norm': 3.096811294555664, 'learning_rate': 0.00056, 'epoch': 6.5}
{'loss': 5.7377, 'grad_norm': 3.1163532733917236, 'learning_rate': 0.0005440000000000001, 'epoch': 6.6}
{'loss': 5.7728, 'grad_norm': 3.2206599712371826, 'learning_rate': 0.000528, 'epoch': 6.7}
{'loss': 6.2638, 'grad_norm': 3.0319619178771973, 'learning_rate': 0.0005120000000000001, 'epoch': 6.8}
{'loss': 5.7027, 'grad_norm': 3.0670344829559326, 'learning_rate': 0.000496, 'epoch': 6.9}
{'loss': 5.8557, 'grad_norm': 3.603466510772705, 'learning_rate': 0.00048, 'epoch': 7.0}
{'eval_loss': 7.427225589752197, 'eval_runtime': 3.585, 'eval_samples_per_second': 36.82, 'eval_steps_per_second': 18.41, 'epoch': 7.0}
{'loss': 5.9017, 'grad_norm': 4.428425312042236, 'learning_rate': 0.000464, 'epoch': 7.1}
{'loss': 5.9083, 'grad_norm': 2.787282943725586, 'learning_rate': 0.00044800000000000005, 'epoch': 7.2}
{'loss': 5.6358, 'grad_norm': 2.867917060852051, 'learning_rate': 0.00043200000000000004, 'epoch': 7.3}
{'loss': 5.6371, 'grad_norm': 2.9054677486419678, 'learning_rate': 0.00041600000000000003, 'epoch': 7.4}
{'loss': 5.8212, 'grad_norm': 3.402113437652588, 'learning_rate': 0.0004, 'epoch': 7.5}
{'loss': 5.8516, 'grad_norm': 3.346601724624634, 'learning_rate': 0.000384, 'epoch': 7.6}
{'loss': 6.0186, 'grad_norm': 3.070406198501587, 'learning_rate': 0.00036800000000000005, 'epoch': 7.7}
{'loss': 5.7525, 'grad_norm': 3.3963496685028076, 'learning_rate': 0.00035200000000000005, 'epoch': 7.8}
{'loss': 5.8022, 'grad_norm': 2.892543077468872, 'learning_rate': 0.000336, 'epoch': 7.9}
{'loss': 5.9786, 'grad_norm': 3.0546329021453857, 'learning_rate': 0.00032, 'epoch': 8.0}
{'eval_loss': 7.358036994934082, 'eval_runtime': 3.5933, 'eval_samples_per_second': 36.735, 'eval_steps_per_second': 18.368, 'epoch': 8.0}
{'loss': 5.8445, 'grad_norm': 3.113985061645508, 'learning_rate': 0.000304, 'epoch': 8.1}
{'loss': 6.0926, 'grad_norm': 2.6908440589904785, 'learning_rate': 0.000288, 'epoch': 8.2}
{'loss': 5.8876, 'grad_norm': 2.6422953605651855, 'learning_rate': 0.00027200000000000005, 'epoch': 8.3}
{'loss': 5.7379, 'grad_norm': 2.834503650665283, 'learning_rate': 0.00025600000000000004, 'epoch': 8.4}
{'loss': 5.6688, 'grad_norm': 3.121640682220459, 'learning_rate': 0.00024, 'epoch': 8.5}
{'loss': 5.686, 'grad_norm': 2.76045560836792, 'learning_rate': 0.00022400000000000002, 'epoch': 8.6}
{'loss': 5.7615, 'grad_norm': 2.6468183994293213, 'learning_rate': 0.00020800000000000001, 'epoch': 8.7}
{'loss': 5.7699, 'grad_norm': 2.9083473682403564, 'learning_rate': 0.000192, 'epoch': 8.8}
{'loss': 5.6954, 'grad_norm': 2.753676176071167, 'learning_rate': 0.00017600000000000002, 'epoch': 8.9}
{'loss': 5.5834, 'grad_norm': 2.6363556385040283, 'learning_rate': 0.00016, 'epoch': 9.0}
{'eval_loss': 7.278623580932617, 'eval_runtime': 3.6116, 'eval_samples_per_second': 36.549, 'eval_steps_per_second': 18.274, 'epoch': 9.0}
{'loss': 5.8715, 'grad_norm': 2.797907829284668, 'learning_rate': 0.000144, 'epoch': 9.1}
{'loss': 5.9073, 'grad_norm': 3.0299575328826904, 'learning_rate': 0.00012800000000000002, 'epoch': 9.2}
{'loss': 5.6865, 'grad_norm': 2.6375668048858643, 'learning_rate': 0.00011200000000000001, 'epoch': 9.3}
{'loss': 5.8669, 'grad_norm': 3.0068442821502686, 'learning_rate': 9.6e-05, 'epoch': 9.4}
{'loss': 5.512, 'grad_norm': 3.010847806930542, 'learning_rate': 8e-05, 'epoch': 9.5}
{'loss': 5.5573, 'grad_norm': 2.7025222778320312, 'learning_rate': 6.400000000000001e-05, 'epoch': 9.6}
{'loss': 5.8036, 'grad_norm': 3.098980188369751, 'learning_rate': 4.8e-05, 'epoch': 9.7}
{'loss': 5.9464, 'grad_norm': 2.8052995204925537, 'learning_rate': 3.2000000000000005e-05, 'epoch': 9.8}
{'loss': 5.7449, 'grad_norm': 2.631751298904419, 'learning_rate': 1.6000000000000003e-05, 'epoch': 9.9}
{'loss': 5.598, 'grad_norm': 2.750969171524048, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 7.3125128746032715, 'eval_runtime': 3.5834, 'eval_samples_per_second': 36.837, 'eval_steps_per_second': 18.418, 'epoch': 10.0}
{'train_runtime': 881.5133, 'train_samples_per_second': 11.798, 'train_steps_per_second': 1.475, 'train_loss': 6.403236512404222, 'epoch': 10.0}
